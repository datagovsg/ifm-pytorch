{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_metrics import apk\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iftorch.algorithms import SVDRecommender, UserItemEmbeddingsFeature\n",
    "from iftorch.dataset import UserItemSet\n",
    "from iftorch.loss import ModifiedMaxWarpLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Train/Test UserItemSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = UserItemSet.load_cls_from_file('trainset', '../data')\n",
    "test_set = UserItemSet.load_cls_from_file('testset', '../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_recommender = SVDRecommender.load_cls_from_file('svd_recommender_test', '../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_embeddings = UserItemEmbeddingsFeature(\n",
    "    trainable=True,\n",
    "    user_embeddings=svd_recommender.user_embeddings_,\n",
    "    item_embeddings=svd_recommender.item_embeddings_.transpose()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossProduct(nn.Module):\n",
    "    def __init__(self, is_cuda=True):\n",
    "        super(CrossProduct, self).__init__()\n",
    "        if is_cuda:\n",
    "            self._torch = torch.cuda\n",
    "        else:\n",
    "            self._torch = torch\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        user_embeddings = inputs[0]\n",
    "        item_embeddings = inputs[1]\n",
    "\n",
    "        return torch.sum(user_embeddings * item_embeddings, dim=1, keepdim=True)\n",
    "\n",
    "cross_product_model = CrossProduct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    chain(user_item_embeddings.user_embeddings.parameters(),\n",
    "          user_item_embeddings.item_embeddings.parameters()), \n",
    "    lr=1e-5, \n",
    "    eps=1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_max_warp_loss = ModifiedMaxWarpLoss(\n",
    "    num_epochs=100,\n",
    "    batch_size=30,\n",
    "    verbose=10.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_method(self, users):\n",
    "    \"\"\"Scoring method after training UserItemEmbeddingsFeature.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    users : np.ndarray[int], [len(users), 1]\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    np.ndarra[float], [len(users) x self._features.n_items,]\n",
    "    \"\"\"\n",
    "    user_embeddings = (\n",
    "        self._features\n",
    "        .user_embeddings(self._torch.LongTensor(users))\n",
    "        .cpu().detach().numpy()\n",
    "    )\n",
    "\n",
    "    item_embeddings = (\n",
    "        self._features.item_embeddings(\n",
    "            self._torch.LongTensor(np.arange(self._features.n_items))\n",
    "        ).cpu().detach().numpy()\n",
    "    )\n",
    "\n",
    "    return np.reshape(user_embeddings.dot(item_embeddings.transpose()), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 | Loss : 3.7300e+00\n",
      "Epoch : 1 | Loss : 3.7292e+00\n",
      "Epoch : 2 | Loss : 3.7301e+00\n",
      "Epoch : 3 | Loss : 3.7160e+00\n",
      "Epoch : 4 | Loss : 3.7091e+00\n",
      "Epoch : 5 | Loss : 3.7020e+00\n",
      "Epoch : 6 | Loss : 3.6868e+00\n",
      "Epoch : 7 | Loss : 3.6900e+00\n",
      "Epoch : 8 | Loss : 3.6763e+00\n",
      "Epoch : 9 | Loss : 3.6631e+00\n",
      "Epoch : 10 | Loss : 3.6664e+00\n",
      "Epoch : 11 | Loss : 3.6617e+00\n",
      "Epoch : 12 | Loss : 3.6398e+00\n",
      "Epoch : 13 | Loss : 3.6366e+00\n",
      "Epoch : 14 | Loss : 3.6278e+00\n",
      "Epoch : 15 | Loss : 3.6268e+00\n",
      "Epoch : 16 | Loss : 3.6242e+00\n",
      "Epoch : 17 | Loss : 3.6131e+00\n",
      "Epoch : 18 | Loss : 3.6023e+00\n",
      "Epoch : 19 | Loss : 3.5900e+00\n",
      "Epoch : 20 | Loss : 3.5813e+00\n",
      "Epoch : 21 | Loss : 3.5666e+00\n",
      "Epoch : 22 | Loss : 3.5664e+00\n",
      "Epoch : 23 | Loss : 3.5698e+00\n",
      "Epoch : 24 | Loss : 3.5431e+00\n",
      "Epoch : 25 | Loss : 3.5372e+00\n",
      "Epoch : 26 | Loss : 3.5255e+00\n",
      "Epoch : 27 | Loss : 3.5068e+00\n",
      "Epoch : 28 | Loss : 3.5042e+00\n",
      "Epoch : 29 | Loss : 3.5105e+00\n",
      "Epoch : 30 | Loss : 3.4942e+00\n",
      "Epoch : 31 | Loss : 3.5021e+00\n",
      "Epoch : 32 | Loss : 3.4940e+00\n",
      "Epoch : 33 | Loss : 3.4831e+00\n",
      "Epoch : 34 | Loss : 3.4603e+00\n",
      "Epoch : 35 | Loss : 3.4586e+00\n",
      "Epoch : 36 | Loss : 3.4566e+00\n",
      "Epoch : 37 | Loss : 3.4459e+00\n",
      "Epoch : 38 | Loss : 3.4469e+00\n",
      "Epoch : 39 | Loss : 3.4430e+00\n",
      "Epoch : 40 | Loss : 3.4416e+00\n",
      "Epoch : 41 | Loss : 3.4321e+00\n",
      "Epoch : 42 | Loss : 3.4386e+00\n",
      "Epoch : 43 | Loss : 3.4316e+00\n",
      "Epoch : 44 | Loss : 3.4341e+00\n",
      "Epoch : 45 | Loss : 3.4331e+00\n",
      "Epoch : 46 | Loss : 3.4202e+00\n",
      "Epoch : 47 | Loss : 3.4265e+00\n",
      "Epoch : 48 | Loss : 3.4017e+00\n",
      "Epoch : 49 | Loss : 3.4171e+00\n",
      "Epoch : 50 | Loss : 3.4017e+00\n",
      "Epoch : 51 | Loss : 3.4057e+00\n",
      "Epoch : 52 | Loss : 3.4170e+00\n",
      "Epoch : 53 | Loss : 3.3853e+00\n",
      "Epoch : 54 | Loss : 3.3905e+00\n",
      "Epoch : 55 | Loss : 3.3931e+00\n",
      "Epoch : 56 | Loss : 3.3918e+00\n",
      "Epoch : 57 | Loss : 3.3773e+00\n",
      "Epoch : 58 | Loss : 3.3652e+00\n",
      "Epoch : 59 | Loss : 3.3649e+00\n",
      "Epoch : 60 | Loss : 3.3716e+00\n",
      "Epoch : 61 | Loss : 3.3566e+00\n",
      "Epoch : 62 | Loss : 3.3535e+00\n",
      "Epoch : 63 | Loss : 3.3545e+00\n",
      "Epoch : 64 | Loss : 3.3340e+00\n",
      "Epoch : 65 | Loss : 3.3470e+00\n",
      "Epoch : 66 | Loss : 3.3167e+00\n",
      "Epoch : 67 | Loss : 3.3235e+00\n",
      "Epoch : 68 | Loss : 3.3116e+00\n",
      "Epoch : 69 | Loss : 3.3208e+00\n",
      "Epoch : 70 | Loss : 3.3086e+00\n",
      "Epoch : 71 | Loss : 3.3039e+00\n",
      "Epoch : 72 | Loss : 3.3116e+00\n",
      "Epoch : 73 | Loss : 3.2964e+00\n",
      "Epoch : 74 | Loss : 3.2913e+00\n",
      "Epoch : 75 | Loss : 3.2838e+00\n",
      "Epoch : 76 | Loss : 3.2922e+00\n",
      "Epoch : 77 | Loss : 3.2739e+00\n",
      "Epoch : 78 | Loss : 3.2679e+00\n",
      "Epoch : 79 | Loss : 3.2742e+00\n",
      "Epoch : 80 | Loss : 3.2693e+00\n",
      "Epoch : 81 | Loss : 3.2641e+00\n",
      "Epoch : 82 | Loss : 3.2685e+00\n",
      "Epoch : 83 | Loss : 3.2486e+00\n",
      "Epoch : 84 | Loss : 3.2501e+00\n",
      "Epoch : 85 | Loss : 3.2549e+00\n",
      "Epoch : 86 | Loss : 3.2437e+00\n",
      "Epoch : 87 | Loss : 3.2193e+00\n",
      "Epoch : 88 | Loss : 3.2428e+00\n",
      "Epoch : 89 | Loss : 3.2276e+00\n",
      "Epoch : 90 | Loss : 3.2267e+00\n",
      "Epoch : 91 | Loss : 3.2309e+00\n",
      "Epoch : 92 | Loss : 3.2219e+00\n",
      "Epoch : 93 | Loss : 3.2035e+00\n",
      "Epoch : 94 | Loss : 3.2084e+00\n",
      "Epoch : 95 | Loss : 3.2173e+00\n",
      "Epoch : 96 | Loss : 3.2019e+00\n",
      "Epoch : 97 | Loss : 3.1991e+00\n",
      "Epoch : 98 | Loss : 3.1963e+00\n",
      "Epoch : 99 | Loss : 3.1877e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModifiedMaxWarpLoss(batch_size=30, gap=1.0, is_cuda=True, max_abs_score=100.0,\n",
       "          num_epochs=100, num_negative_samples=100, verbose=10.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_max_warp_loss.fit(train_set, cross_product_model, optimizer, user_item_embeddings, scoring_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_embeddings.save_to_file(\n",
    "    'trained_user_item_embeddings',\n",
    "    '../data'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModifiedMaxWarpLoss(batch_size=30, gap=1.0, is_cuda=True, max_abs_score=100.0,\n",
       "          num_epochs=0, num_negative_samples=100, verbose=10.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_embeddings = UserItemEmbeddingsFeature.load_cls_from_file(\n",
    "    'trained_user_item_embeddings', '../data'\n",
    ")\n",
    "\n",
    "modified_max_warp_loss = ModifiedMaxWarpLoss(\n",
    "    num_epochs=0,\n",
    "    batch_size=30,\n",
    "    verbose=10.0\n",
    ")\n",
    "\n",
    "modified_max_warp_loss.fit(train_set,\n",
    "                           cross_product_model,\n",
    "                           optimizer,\n",
    "                           user_item_embeddings,\n",
    "                           scoring_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2recommended_items = modified_max_warp_loss.predict(\n",
    "    test_set, \n",
    "    train_set, \n",
    "    remove_users_not_in_train=True,\n",
    "    max_score_to_filter=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapk_scores = []\n",
    "for user, recommended_items in user2recommended_items.items():\n",
    "    mapk_scores.append(apk(test_set.user2items_inner[user],\n",
    "                           recommended_items,\n",
    "                           k=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007349616576189105"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mapk_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ifm-pytorch",
   "language": "python",
   "name": "ifm-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
